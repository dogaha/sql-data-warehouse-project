# Data Warehouse and Analytics Project
## Disclainmer
This project was created by following a tutorial created by a youtuber named 'Data With Bara'. However, I made some changes to the project by implementing python code for the multiple sql queries and DDL creation. For the DDL creation i used pandas to find to get the general data type then for more specific data types (strings and dates = objects) I checked the actual data to see if it was a date. To run SQL queries I used pypyodbt to run sql server. In addition to this, a config file was added to make the python files slightly eaiser to use. the config file contains server name of the sql server used (note that it dosent work if sql server requires a username / password )

Also, the order to run the code is...<br>
init_databasew.sql => ddl_bronze.py => proc_load_bronze.py => ddl_silver.py => proc_load_silver.py => ddl_gold.sql

---
Welcome to the **Data Warehouse** repository! ğŸš€  
This project demonstrates a comprehensive data warehousing and analytics solution, from building a data warehouse to generating actionable insights. Designed as a portfolio project, it highlights industry best practices in data engineering and analytics.

## ğŸ—ï¸ Data Architecture

The data architecture for this project follows Medallion Architecture **Bronze**, **Silver**, and **Gold** layers:
![Data Architecture](docs/data_architecture.png)

1. **Bronze Layer**: Stores raw data as-is from the source systems. Data is ingested from CSV Files into SQL Server Database.
2. **Silver Layer**: This layer includes data cleansing, standardization, and normalization processes to prepare data for analysis.
3. **Gold Layer**: Houses business-ready data modeled into a star schema required for reporting and analytics.

---
## ğŸ“– Project Overview

This project involves:

1. **Data Architecture**: Designing a Modern Data Warehouse Using Medallion Architecture **Bronze**, **Silver**, and **Gold** layers.
2. **ETL Pipelines**: Extracting, transforming, and loading data from source systems into the warehouse.
3. **Data Modeling**: Developing fact and dimension tables optimized for analytical queries.
4. **Analytics & Reporting**: Creating SQL-based reports and dashboards for actionable insights.

---

## ğŸš€ Project Requirements

### Building the Data Warehouse (Data Engineering)

#### Objective
Develop a modern data warehouse using SQL Server to consolidate sales data, enabling analytical reporting and informed decision-making.

#### Specifications
- **Data Sources**: Import data from two source systems (ERP and CRM) provided as CSV files.
- **Data Quality**: Cleanse and resolve data quality issues prior to analysis.
- **Integration**: Combine both sources into a single, user-friendly data model designed for analytical queries.
- **Scope**: Focus on the latest dataset only; historization of data is not required.
- **Documentation**: Provide clear documentation of the data model to support both business stakeholders and analytics teams.

---
## ğŸ“‚ Repository Structure
```
data-warehouse-project/
â”‚
â”œâ”€â”€ datasets/                           # Raw datasets used for the project (ERP and CRM data)
â”‚
â”œâ”€â”€ docs/                               # Project documentation and architecture details                     
â”‚   â”œâ”€â”€ data_architecture.png           # png file shows the project's architecture
â”‚   â”œâ”€â”€ data_catalog.md                 # Catalog of datasets, including field descriptions and metadata
â”‚   â”œâ”€â”€ data_flow_diagram.png           # png file for the data flow diagram
â”‚   â”œâ”€â”€ data_integration_model.png      # png file for the data integration diagram
â”‚   â”œâ”€â”€ data_models.png                 # png file for data models (star schema)
â”‚   â”œâ”€â”€ naming-conventions.md           # Consistent naming guidelines for tables, columns, and files
â”‚
â”œâ”€â”€ scripts/                            # SQL scripts for ETL and transformations
â”‚   â”œâ”€â”€ bronze/                         # Scripts for extracting and loading raw data
â”‚   â”œâ”€â”€ silver/                         # Scripts for cleaning and transforming data
â”‚   â”œâ”€â”€ gold/                           # Scripts for creating analytical models
â”‚
â”œâ”€â”€ tests/                              # Test scripts and quality files
â”‚
â”œâ”€â”€ README.md                           # Project overview and instructions
â”œâ”€â”€ LICENSE                             # License information for the repository
â”œâ”€â”€ .gitignore                          # Files and directories to be ignored by Git
â””â”€â”€ config.json                         # the config file forr the python files
```
---
---

## ğŸ›¡ï¸ License

This project is licensed under the [MIT License](LICENSE). You are free to use, modify, and share this project with proper attribution.

## ğŸŒŸ About Me

Hi there! I'm **Ethan Vu**. Iâ€™m a student at the University Of Houston Clear Lake and am an aspiring Data Engineer!
